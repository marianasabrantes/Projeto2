{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpmath import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "leitura = pd.ExcelFile('tweets_Nike_1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_treinamento = pd.read_excel(leitura, 'Treinamento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_teste = pd.read_excel(leitura, 'Teste') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(':', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('@', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('*', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('“', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('.', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(')', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('(', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('_', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(';', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(',', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('&', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('/', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('#', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('%', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('$', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"!\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"?\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"-\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"+\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"=\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('rt', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"\\n\", '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(':', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('@', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('*', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('“', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('.', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(')', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('(', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('_', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(';', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(',', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('&', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('/', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('#', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('%', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('$', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"!\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"?\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"-\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"+\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"=\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('rt', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"\\n\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel = tweets_treinamento[tweets_treinamento['classificacao'] == 1]\n",
    "irrel = tweets_treinamento[tweets_treinamento['classificacao'] == 0]\n",
    "tweets_treinamento['Treinamento'] = tweets_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrel= []\n",
    "for i in tweets_treinamento['Treinamento']:\n",
    "    lrel.append(rel['Treinamento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "lirrel= []\n",
    "for i in tweets_treinamento['Treinamento']:\n",
    "    lirrel.append(irrel['Treinamento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_irrel = tweets_treinamento.classificacao[tweets_treinamento.classificacao == 0].count()\n",
    "n_rel = tweets_treinamento.classificacao[tweets_treinamento.classificacao == 1].count()\n",
    "total = n_rel + n_irrel\n",
    "\n",
    "prob_irrelevante = n_irrel/ total\n",
    "prob_relevante = n_rel/ total\n",
    "\n",
    "tweets = []\n",
    "relevante = []\n",
    "irrelevante = []\n",
    "\n",
    "for palavra in tweets_treinamento['Treinamento']:\n",
    "    palavra = palavra.lower()\n",
    "    \n",
    "for palavra in rel['Treinamento']:\n",
    "    relevante.append(palavra.split())\n",
    "    \n",
    "for palavra in irrel['Treinamento']:\n",
    "    irrelevante.append(palavra.split())\n",
    "\n",
    "for each in tweets_treinamento['Treinamento']:\n",
    "    tweets.append(each.split())\n",
    "\n",
    "dic_rel = {}\n",
    "dic_irrel = {}\n",
    "dic_tweet = {}\n",
    "\n",
    "Ln_rel = []\n",
    "Ln_irrel = []\n",
    "TD = []\n",
    "\n",
    "for f in relevante:\n",
    "    for p in f:\n",
    "        Ln_rel.append(p)\n",
    "        dic_rel[word] = Ln_rel.count(p)\n",
    "\n",
    "for f in irrelevante:\n",
    "    for p in f:\n",
    "        Ln_irrel.append(p)\n",
    "        dic_irrel[p] = Ln_irrel.count(p)\n",
    "\n",
    "for f in tweets:\n",
    "    for p in f:\n",
    "        TD.append(p)\n",
    "        dic_tweet[p] = TD.count(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_relevante = len(rel)/len(tweets_treinamento)\n",
    "P_irrelevante = len(irrel)/len(tweets_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5378\n",
      "377\n",
      "5001\n"
     ]
    }
   ],
   "source": [
    "print(len(TD))\n",
    "print(len(Ln_rel))\n",
    "print(len(Ln_irrel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592\n",
      "5378\n"
     ]
    }
   ],
   "source": [
    "new= list(set(TD))\n",
    "print(len(new))\n",
    "print(len(TD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = len(Ln_rel)/len(TD)\n",
    "ir = len(Ln_irrel)/len(TD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'nike'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-41e1735b19d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLn_rel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mp_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpl\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdic_rel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpl\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLn_rel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLn_irrel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'nike'"
     ]
    }
   ],
   "source": [
    "p_r = {}\n",
    "p_ir = {}\n",
    "\n",
    "for pl in Ln_rel:\n",
    "    p_r[pl] = (dic_rel[pl] + 1)/ (len(new) + len(Ln_rel))\n",
    "\n",
    "for pl in Ln_irrel:\n",
    "    p_ir[pl] = (dic_irrel[pl] + 1)/ (len(new) + len(Ln_irrel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "soma_rel = sum(p_r.values())\n",
    "soma_irrel = sum(p_ir.values())\n",
    "\n",
    "print(soma_rel + soma_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculaProbR(tweet):\n",
    "    a = 1\n",
    "    T_tweet = 0\n",
    "    \n",
    "    for frase in relevantes_separados:\n",
    "        T_tweet += len(frase)\n",
    "        \n",
    "        for j in frase:\n",
    "            if j.lower() == tweet.lower():\n",
    "                a += 1\n",
    "                \n",
    "    return a/(T_tweet + len(repeticoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculaProbI(tweet):\n",
    "    a = 1\n",
    "    T_tweet = 0\n",
    "    \n",
    "    for frase in irrelevantes_separados:\n",
    "        T_tweet += len(frase)\n",
    "        \n",
    "        for j in frase:\n",
    "            if j.lower() == tweet.lower():\n",
    "                a += 1\n",
    "                \n",
    "    return a/(T_tweet + len(repeticoes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'varifica' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-5e4a85c1ca6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mLtweets_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mverifica_pronto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvarifica\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLtweets_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[0mresposta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_teste\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Unnamed: 1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Relevancia'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRelevancia\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'varifica' is not defined"
     ]
    }
   ],
   "source": [
    "def verifica(td_separado):\n",
    "    varifica_pronto = []\n",
    "\n",
    "    for t in td_separado: \n",
    "        \n",
    "        td_s = t.split()\n",
    "        \n",
    "        Prob_relevantes = []\n",
    "        Prob_irrelevantes = []\n",
    "                \n",
    "        for p in td_s:\n",
    "                        \n",
    "            Prob_relevantes.append(CalculaProbR(p))\n",
    "            Prob_irrelevantes.append(CalculaProbI(p))\n",
    "\n",
    "        relevante = 1\n",
    "        irrelevante = 1\n",
    "\n",
    "        for i in Prob_relevantes:\n",
    "            relevante *= i\n",
    "\n",
    "        for i in Prob_irrelevantes:\n",
    "            irrelevante *= i\n",
    "\n",
    "        relevante_tweet = relevante * Prob_relevantes\n",
    "        irrelevante_tweet = irrelevante * Prob_irrelevantes\n",
    "\n",
    "        if relevate > irrelevante:\n",
    "            verifica_pronto.append('Relevante')\n",
    "        else:\n",
    "            verifica_pronto.append('Irrelevante')\n",
    "    return varifica_pronto\n",
    "\n",
    "Ltweets_test = []\n",
    "for tweet in tweets_teste:\n",
    "    Ltweets_test.append(tweet)\n",
    "\n",
    "verifica_pronto = varifica(Ltweets_test)\n",
    "\n",
    "resposta = tweets_teste.rename(index=str, columns={'Unnamed: 1':'Relevancia'}).Relevancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resposta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-e0622e09277b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mverneg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresposta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresposta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mverifica_pronto\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mresposta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Relevante'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mverpos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'resposta' is not defined"
     ]
    }
   ],
   "source": [
    "falpos = 0\n",
    "falneg = 0\n",
    "verpos = 0\n",
    "verneg = 0\n",
    "\n",
    "for i in range(len(resposta)):\n",
    "    if resposta[i] == verifica_pronto[i] and resposta[i] == 'Relevante':\n",
    "        verpos += 1\n",
    "    elif resposta[i] == verifica_pronto[i] and resposta[i] == 'Irrelevante':\n",
    "        verneg += 1\n",
    "    elif resposta[i] != verifica_pronto[i] and resposta[i] == 'Relevante':\n",
    "        falneg += 1\n",
    "    else:\n",
    "        falpos += 1\n",
    "\n",
    "falpos /= len(verifica_pronto)\n",
    "falneg /= len(verifica_pronto)\n",
    "verpos /= len(verifica_pronto)\n",
    "verneg /= len(verifica_pronto)\n",
    "\n",
    "\n",
    "print(\"Negativo Falso: {}%\".format(falneg*100))\n",
    "print(\"Positivo Falso: {}%\".format(falpos*100))\n",
    "print(\"Negativo Verdadeiro: {}%\".format(verneg*100))\n",
    "print(\"Positivo Verdadeiro: {}%\".format(verpos*100))\n",
    "\n",
    "len(verifica_pronto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
