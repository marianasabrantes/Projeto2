{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mpmath import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura do excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "leitura = pd.ExcelFile('tweets_Nike_1.xlsx')\n",
    "tweets_treinamento = pd.read_excel(leitura, 'Treinamento')\n",
    "tweets_teste = pd.read_excel(leitura, 'Teste') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpando os tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(':', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('@', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('*', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('“', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('.', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(')', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('(', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('_', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(';', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(',', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('&', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('/', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('#', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('%', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('$', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"!\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"?\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"-\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"+\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"=\", '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace('rt', '', regex=False)\n",
    "tweets_treinamento.Treinamento = tweets_treinamento.Treinamento.str.replace(\"\\n\", '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(':', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('@', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('*', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('“', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('.', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(')', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('(', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('_', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(';', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(',', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('&', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('/', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('#', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('%', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('$', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"!\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"?\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"-\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"+\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"=\", '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace('rt', '')\n",
    "tweets_teste.Teste = tweets_teste.Teste.str.replace(\"\\n\", '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adicionando os tweets limpos em uma lista\n",
    "\n",
    "Nesta célula, criamos uma lista na qual os tweets da tabela treinamento e teste serão adicionados a uma tabela. Os tweets foram separados nas tabelas em relevantes e irrelevantes.\n",
    "\n",
    "Tweets relevantes: são tweets que interferem diretamente na marca, ou seja, podem interferir na quantidade de clientes para a marca. \n",
    "    Tweets irrelevantes: sãao tweets que nao interferem na marca, ou seja, memes, piadas ou algo como \"usei nike ontem\" ARRUAMAR!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel_treinamento = tweets_treinamento[(tweets_treinamento['classificacao'] == 1)]\n",
    "irrel_treinamento = tweets_treinamento[(tweets_treinamento['classificacao'] == 0)]\n",
    "tweets_treinamento['Treinamento'] = tweets_treinamento\n",
    "\n",
    "rel_teste = tweets_teste[(tweets_teste['classificacao'] == 1)]\n",
    "irrel_teste = tweets_teste[(tweets_teste['classificacao'] == 0)]\n",
    "tweets_teste['Teste'] = tweets_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split e tirando capslock\n",
    "\n",
    "Nesta célula criamos novas listas vazias, nas quais vão receber as strings de cada tweet separados e todos sem capslock, caso exista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrel= []\n",
    "lirrel= []\n",
    "ltodos = []\n",
    "\n",
    "for tweet in tweets_treinamento['Treinamento']:\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "for tweet in rel_treinamento['Treinamento']:\n",
    "    lrel.append(tweet.split())\n",
    "    \n",
    "for tweet in irrel_treinamento['Treinamento']:\n",
    "    lirrel.append(tweet.split())\n",
    "    \n",
    "for tweet in tweets_treinamento['Treinamento']:\n",
    "    ltodos.append(tweet.split())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contando número de tweets e calculando a probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------- contando quantidade de cada tweet marcado como relevante e irrelevante ---------------------------#\n",
    "qnt_irrel = tweets_treinamento.classificacao[tweets_treinamento.classificacao == 0].count()\n",
    "qnt_rel = tweets_treinamento.classificacao[tweets_treinamento.classificacao == 1].count()\n",
    "total_qnt = qnt_rel + qnt_irrel\n",
    "\n",
    "#------------------------------------ calculando a P de um tweet ser relevante ou irrelevante ---------------------------------#\n",
    "prob_irrelevante = qnt_irrel/ total_qnt\n",
    "prob_relevante = qnt_rel/ total_qnt\n",
    "\n",
    "#------------------------------------- criando dicionarios vazios para a contagem de palavras ---------------------------------#\n",
    "dic_rel = {}\n",
    "dic_irrel = {}\n",
    "dic_tweet = {}\n",
    "\n",
    "#--------------------------------------- criando listas vazias para as palavras que aparecem ---------------------------------# \n",
    "Ln_rel = []\n",
    "Ln_irrel = []\n",
    "TD = []\n",
    "#------------------------------------- contando quantas vezes cada palavra aparece nos tweets --------------------------------#\n",
    "for frase in lrel:\n",
    "    for palavrinha in frase:\n",
    "        Ln_rel.append(palavrinha)\n",
    "        dic_rel[palavrinha] = Ln_rel.count(palavrinha)\n",
    "\n",
    "for frase in lirrel:\n",
    "    for palavrinha in frase:\n",
    "        Ln_irrel.append(palavrinha)\n",
    "        dic_irrel[palavrinha] = Ln_irrel.count(palavrinha)\n",
    "\n",
    "for frase in ltodos:\n",
    "    for palavrinha in frase:\n",
    "        TD.append(palavrinha)\n",
    "        dic_tweet[palavrinha] = TD.count(palavrinha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descobrindo os tamanhos das listas e adicionando todos os tweets separados a uma lista "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5380\n",
      "378\n",
      "5002\n",
      "1593\n",
      "5380\n"
     ]
    }
   ],
   "source": [
    "print(len(TD))\n",
    "print(len(Ln_rel))\n",
    "print(len(Ln_irrel))\n",
    "\n",
    "#--------------------------------------------- criando uma lista que tera as palavras sem repetição --------------------------#\n",
    "sem_repeticao= list(set(TD))\n",
    "print(len(sem_repeticao))\n",
    "print(len(TD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teorema de Bayers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ criando dicionarios para descobrir a probabilidade da palavra ser relevante ou irrelevante ---------------------#\n",
    "relevantes = {}\n",
    "irrelevantes = {}\n",
    "\n",
    "for palavra in Ln_rel:\n",
    "    relevantes[palavra] = (dic_rel[palavra] + 1)/ (len(sem_repeticao) + len(Ln_rel))\n",
    "\n",
    "for palavra in Ln_irrel:\n",
    "    relevantes[palavra] = (dic_irrel[palavra] + 1)/ (len(sem_repeticao) + len(Ln_irrel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0336602495086897\n"
     ]
    }
   ],
   "source": [
    "r = len(Ln_rel)/len(TD)\n",
    "ir = len(Ln_irrel)/len(TD)\n",
    "\n",
    "soma_rel = sum(relevantes.values())\n",
    "soma_irrel = sum(irrelevantes.values())\n",
    "\n",
    "print(soma_rel + soma_irrel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "classific = []\n",
    "for tweet in tweets_teste['Teste']:\n",
    "    tweets_frase = []\n",
    "    tweets_frase.append(tweet.split())\n",
    "    for palavra in tweets_frase:\n",
    "        for palavrinha in palavra:\n",
    "            tweets_frase = []\n",
    "            tweets_frase.append(palavrinha)                          \n",
    "            for palavra in tweets_frase:\n",
    "                Probfrase_rel = 1\n",
    "                Probtweets_rel = 0\n",
    "                Probfrase_irrel = 1\n",
    "                Probtweets_irrel = 0\n",
    "                \n",
    "                if palavra in relevantes:\n",
    "                    Probtweets_r = relevantes[palavra]\n",
    "                    Probfrase_rel *= Probtweets_r\n",
    "                elif palavra in irrelevantes:\n",
    "                    Probtweets_ir = irrelevantes[palavra]\n",
    "                    Probfrase_rel *= Probtweets_ir\n",
    "                else:\n",
    "                    Probtweets_ir = 1/(len(Ln_irrel) + len(sem_repeticao))\n",
    "                    Probtweets_rel = 1/(len(Ln_rel) + len(sem_repeticao))\n",
    "                    Probfrase_rel *= Probtweets_rel\n",
    "                    Probfrase_irrel *= Probtweets_irrel\n",
    "    if Probfrase_rel > Probfrase_irrel:\n",
    "        classific.append(1)\n",
    "    else:\n",
    "        classific.append(0)\n",
    "        \n",
    "tweets_teste['Computador'] = classific\n",
    "\n",
    "verdadeiro_positivo = 0\n",
    "verdadeiro_negativo = 0\n",
    "falso_positivo = 0\n",
    "falso_negativo = 0\n",
    "\n",
    "for i in range(len(tweets_teste)):\n",
    "    if tweets_teste['Computador'][i] == 1 and tweets_teste['classificacao'][i] == 1:\n",
    "        verdadeiro_positivo += 1\n",
    "    elif tweets_teste['Computador'][i] == 0 and tweets_teste['classificacao'][i] == 1:\n",
    "        falso_negativo += 1\n",
    "    elif tweets_teste['Computador'][i] == 0 and tweets_teste['classificacao'][i] == 0:\n",
    "        verdadeiro_negativo += 1\n",
    "    else:\n",
    "        falso_positivo += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de positivos verdadeiros é: 4.5 %\n",
      "A porcentagem de negativos verdadeiros é: 47.0 %\n",
      "A porcentagem de positivos falsos é: 41.5 %\n",
      "A porcentagem de negativos falsos é: 7.0 %\n"
     ]
    }
   ],
   "source": [
    "print('A porcentagem de positivos verdadeiros é:', verdadeiro_positivo/2,'%')\n",
    "print('A porcentagem de negativos verdadeiros é:', verdadeiro_negativo/2,'%')\n",
    "print('A porcentagem de positivos falsos é:', falso_positivo/2,'%')\n",
    "print('A porcentagem de negativos falsos é:', falso_negativo/2,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantidade dos respectivos Positivos e Negativos (sem porcentagem):')\n",
    "tweets_treinamento.Novas_Medidas.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "r = df2.Novas_Medidas.value_counts()/len(Res)*100\n",
    "t = r.reindex(['positivos falsos','positivos verdadeiros','negativos verdadeiros','negativos falsos'])\n",
    "plot = t.plot(kind='pie',title='Novas Medidas exigidas pelo professor (%)',autopct='%.1f',figsize=(7, 7))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se concluir que o programa não é eficaz. O valor alto dos positivos falsos, se dá pela citação do nome da marca nos tweets de forma que não seja relevante a empresa, como um meme ou uma piada. A porcentagem de negativos falsos pode ser explicada pelo padrão que os tweets irrelevantes seguem, facilitando a análise. O valor de negativos falsos ser baixo, significa uma coisa boa pois, não receber uma informação que seja relevante para a sua empresa significa deixar de receber um feedback de um usuário. Apesar de receber informações desnecessárias, possuir um percentual alto de positivos falso é melhor do que um percentual alto de negativo falso, porque assim, a empresa perdeu pouca informação relevante. O valor de positivo verdadeiro ser baixo, significa que poucas palavras nos tweets são positivas, e para um melhor análise, teríamos que ter uma base de dados bem maior.\n",
    "\n",
    "O programa não é preciso pois, existem fatores que comprometem a análise dos tweets, como o sarcasmo. Não podemos confundi-lo com ironia, já que o sarcasmo é a forma de que as pessoas utilizam geralmente para criticar algo. O problema do sarcasmo é que ele é identificado através da pontuação da frase e para que isso seja possível, precisaria de um programa que analisasse tais pontuações, sendo que provavelmente definiria como positivos algumas dessas frases, e mesmo assim não seria totalmente preciso. Já os casos de dupla negação, são aquele que o usuário geralmente escreve a negação por acidente. Um exemplo é a frase “não vi ninguém”, onde que a análise mostra que ela viu uma pessoa, porém ela quis dizer o oposto.  O programa então julgaria negativo algo que era positivo ou o contrário.\n",
    "\n",
    "Se essas e outras alterações fossem aplicadas ao nosso programa, a empresa Nike poderia planejar um processo de expansão do nosso projeto, fazendo com que tivesse uma busca mais ampla, não somente a análise do Twitter, mas em outras grandes redes socias, como Facebook, Instagram, dentre outros. Isso faria com que a empresa tivesse um melhor feedback dos seus usuários, podendo então, desenvolver soluções mais eficazes para uma melhor satisfação."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
